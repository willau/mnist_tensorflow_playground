{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xf1a6be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADg5JREFUeJzt3X+MXXWZx/HPQztt0wKW+qM7QrGt6WrZZi1xpMbirhsE\nkSUp/EHTum5qQhhWkWiCRrbuKjGKLAtFkkV0lEpxWVCjSNUGF6qxq/2xTLG0xaLFOiyt/UF3alok\nLZ328Y97agY653sv95x7z50+71cymXvPc348uZnPnHvv997zNXcXgHhOq7oBANUg/EBQhB8IivAD\nQRF+ICjCDwRF+IGgCD8QFOEHghrbzoONs/E+QZPaeUgglMP6o17yI9bIuoXCb2aXSrpT0hhJX3f3\nW1LrT9AkzbOLihwSQMIGX93wuk0/7TezMZLukvR+SedJWmxm5zW7PwDtVeQ1/wWSnnH3He7+kqQH\nJS0opy0ArVYk/GdLem7Y/Z3Zspcxs14z6zez/qM6UuBwAMrU8nf73b3P3XvcvadL41t9OAANKhL+\nXZKmDbt/TrYMwChQJPyPS5plZjPMbJykRZJWltMWgFZreqjP3YfM7KOSfqzaUN9yd3+qtM4AtFSh\ncX53XyVpVUm9AGgjPt4LBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii\n/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeC\nIvxAUIVm6TWzAUmHJB2TNOTuPWU0BaD1CoU/83fuvr+E/QBoI572A0EVDb9LeszMNppZbxkNAWiP\nok/7L3T3XWb2BkmPmtnT7r5m+ArZP4VeSZqgiQUPB6Ashc787r4r+71P0kOSLhhhnT5373H3ni6N\nL3I4ACVqOvxmNsnMzjhxW9IlkraW1RiA1irytH+qpIfM7MR+/svdHymlKwAt13T43X2HpLeV2As6\n0WljkuUxs2Yk68/enP9Sb/M7v5net6WfmB449mKy/rd3fCK31r1sbXLbCBjqA4Ii/EBQhB8IivAD\nQRF+ICjCDwRVxrf60MnqDNWdNmdWsu5fOpSs/+At307WDx4/nFv73P53JLddu39msv7IWx9O1i/+\nh/W5ta3LkpuGwJkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4JinP9UULumwoj+8MGTLq70Mmu/eFey\nnhqnl6Q5a69N1s+9Pb83rd+c3HbsGX9I1vV0urxqx1/l1s7VlvTGAXDmB4Ii/EBQhB8IivADQRF+\nICjCDwRF+IGgGOc/BTyzbF5u7TcL0+P4P3jxzGT9Czdfl6yf+411yXoRg1fMqbPGz5LVwwcmlNfM\nKYgzPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVXec38yWS7pc0j53n5MtmyLpW5KmSxqQtNDdD7Su\nzdgOX57+Tv6TV30pt/ajF6ckt/3K4iuS9Sn9rRvHr2fyh54rtP2Z27pK6uTU1MiZ/15Jl75i2Y2S\nVrv7LEmrs/sARpG64Xf3NZIGX7F4gaQV2e0VktKnDwAdp9nX/FPdfXd2e4+kqSX1A6BNCr/h5+4u\nyfPqZtZrZv1m1n9UR4oeDkBJmg3/XjPrlqTs9768Fd29z9173L2nS+ObPByAsjUb/pWSlmS3l0hK\nT5cKoOPUDb+ZPSBpnaS3mNlOM7ta0i2SLjaz7ZLem90HMIrUHed398U5pYtK7iWssd1/kay/7+b0\n99ZPS/wP//LCK5Pb+i+3JuutdPzd5yfrP3xrX509jElWJ28fepUdxcIn/ICgCD8QFOEHgiL8QFCE\nHwiK8ANBcenuDvDbD89I1le+dlWyPv/JD+TWXvPLp5rqqWGJ6cEl6eCi/MuKf+ffbktuO1YTk/XP\n709f2nvCqo3JenSc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMb5O8D8S7YU2n7yp/OvkJR7fbUG\njZ12TrK+/d/Tlwbf9u4vJ6rpcfwHX3h9sv6Lj6QvaW7HNyXr0XHmB4Ii/EBQhB8IivADQRF+ICjC\nDwRF+IGgGOfvAD/ZMju9wrQ1yfLEO3MnTNK2x96V3Pbw9JeS9c/PfyhZX3T688l6Ef/6yFXJ+qxf\nrG/ZsSPgzA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQdUd5zez5ZIul7TP3edky26SdI2kE4O8S909\nfXF55Hrz/ceS9fV1JkP/zpt/nNh5otaAgaEX66yR/k5+yr0H35isz771/5J1JuAuppEz/72SLh1h\n+R3uPjf7IfjAKFM3/O6+RtJgG3oB0EZFXvNfb2abzWy5mZ1VWkcA2qLZ8N8taaakuZJ2S7o9b0Uz\n6zWzfjPrP6ojTR4OQNmaCr+773X3Y+5+XNLXJOVeSdHd+9y9x917upR/oUkA7dVU+M2se9jdKyVt\nLacdAO3SyFDfA5LeI+l1ZrZT0mclvcfM5qp2ZegBSde2sEcALWDuRa/s3rgzbYrPszqD1jjJ2JnT\nk/Xt13Tn1iz9EQLNePiFZP25956RrG/+6H+kD5Awe8V1yfqMpeua3ndUG3y1DvqgNbIun/ADgiL8\nQFCEHwiK8ANBEX4gKMIPBMWlu0eBoR0DyfqMf07XU2zSpGT9Tbe+pul9S9L1v8+/dPiMf/nfQvtG\nMZz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoxvmD+/+r/jpZX/eXdxXa/5ab35Zbm3h8Q6F9oxjO\n/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8p7gxk9Pfx7/tM3cX2v8Ne3Ina5IkTfw+39nvVJz5\ngaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCouuP8ZjZN0n2SpkpySX3ufqeZTZH0LUnTJQ1IWujuB1rX\nKpoxePnsZH3++J8W2v/P7kmP87/B1xbaP1qnkTP/kKQb3P08Se+UdJ2ZnSfpRkmr3X2WpNXZfQCj\nRN3wu/tud38iu31I0jZJZ0taIGlFttoKSVe0qkkA5XtVr/nNbLqk8yVtkDTV3XdnpT2qvSwAMEo0\nHH4zO13SdyV93N0PDq+5u6v2fsBI2/WaWb+Z9R/VkULNAihPQ+E3sy7Vgn+/u38vW7zXzLqzerek\nfSNt6+597t7j7j1dGl9GzwBKUDf8ZmaS7pG0zd2XDSutlLQku71E0sPltwegVRr5Su98Sf8oaYuZ\nbcqWLZV0i6Rvm9nVkp6VtLA1LaIus9zSsUWDhXb9/T9OTta7/3Nrsn6s0NHRSnXD7+4/l5T313VR\nue0AaBc+4QcERfiBoAg/EBThB4Ii/EBQhB8Iikt3nwJs3Ljc2vrzHyy070/+9+JkfdZBptkerTjz\nA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQjPOfAvb0vj1RXZfc9umj6Uurzb59T7I+lKyik3HmB4Ii\n/EBQhB8IivADQRF+ICjCDwRF+IGgGOc/BVz9Tz9qetv7D8xL1od+92zT+0Zn48wPBEX4gaAIPxAU\n4QeCIvxAUIQfCIrwA0HVHec3s2mS7pM0VZJL6nP3O83sJknXSHo+W3Wpu69qVaPId89X/z63tuAT\ntya3Xf/JdyTrXdrYVE/ofI18yGdI0g3u/oSZnSFpo5k9mtXucPfbWtcegFapG3533y1pd3b7kJlt\nk3R2qxsD0Fqv6jW/mU2XdL6kE3M0XW9mm81suZmdlbNNr5n1m1n/UaUvGQWgfRoOv5mdLum7kj7u\n7gcl3S1ppqS5qj0zuH2k7dy9z9173L2nS+NLaBlAGRoKv5l1qRb8+939e5Lk7nvd/Zi7H5f0NUkX\ntK5NAGWrG34zM0n3SNrm7suGLe8ettqVkraW3x6AVjF3T69gdqGk/5G0RdLxbPFSSYtVe8rvkgYk\nXZu9OZjrTJvi8+yigi0DyLPBV+ugD1oj6zbybv/PJY20M8b0gVGMT/gBQRF+ICjCDwRF+IGgCD8Q\nFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCqvt9/lIPZva8pOFzPr9O0v62NfDqdGpv\nndqXRG/NKrO3N7n76xtZsa3hP+ngZv3u3lNZAwmd2lun9iXRW7Oq6o2n/UBQhB8Iqurw91V8/JRO\n7a1T+5LorVmV9Fbpa34A1an6zA+gIpWE38wuNbNfm9kzZnZjFT3kMbMBM9tiZpvMrL/iXpab2T4z\n2zps2RQze9TMtme/R5wmraLebjKzXdljt8nMLquot2lm9lMz+5WZPWVmH8uWV/rYJfqq5HFr+9N+\nMxsj6TeSLpa0U9Ljkha7+6/a2kgOMxuQ1OPulY8Jm9nfSHpB0n3uPidbdqukQXe/JfvHeZa7f6pD\nertJ0gtVz9ycTSjTPXxmaUlXSPqQKnzsEn0tVAWPWxVn/gskPePuO9z9JUkPSlpQQR8dz93XSBp8\nxeIFklZkt1eo9sfTdjm9dQR33+3uT2S3D0k6MbN0pY9doq9KVBH+syU9N+z+TnXWlN8u6TEz22hm\nvVU3M4Kpw2ZG2iNpapXNjKDuzM3t9IqZpTvmsWtmxuuy8YbfyS5097mS3i/puuzpbUfy2mu2Thqu\naWjm5nYZYWbpP6vysWt2xuuyVRH+XZKmDbt/TrasI7j7ruz3PkkPqfNmH957YpLU7Pe+ivv5s06a\nuXmkmaXVAY9dJ814XUX4H5c0y8xmmNk4SYskraygj5OY2aTsjRiZ2SRJl6jzZh9eKWlJdnuJpIcr\n7OVlOmXm5ryZpVXxY9dxM167e9t/JF2m2jv+v5X06Sp6yOlrpqQns5+nqu5N0gOqPQ08qtp7I1dL\neq2k1ZK2S3pM0pQO6u2bqs3mvFm1oHVX1NuFqj2l3yxpU/ZzWdWPXaKvSh43PuEHBMUbfkBQhB8I\nivADQRF+ICjCDwRF+IGgCD8QFOEHgvoTQXA2gCJviW0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7cdb588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_train = np.shape(x_train)[0]\n",
    "idx = np.random.randint(n_train)\n",
    "vector = x_train[idx]\n",
    "img = np.reshape(vector, (28, 28))\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow and TensorBoard helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_folder(path=\"tensorflow_summaries/\"):\n",
    "    for file in os.listdir(path):\n",
    "        filepath = path + file\n",
    "        if filepath[-1] != \"/\":\n",
    "            filepath += \"/\"\n",
    "        if os.path.isfile(filepath):\n",
    "            os.remove(filepath)\n",
    "        \n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)\n",
    "        \n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One CNN to rule them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset graph (important for batch normalization and summary)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholder\n",
    "x_input = tf.placeholder(tf.float32, [None, 784])\n",
    "y_input = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    \n",
    "    with tf.name_scope(\"reshape\"):\n",
    "        x_image = tf.reshape(x_input, [-1, 28, 28, 1])\n",
    "        \n",
    "    with tf.name_scope(\"1st_convolution\"):\n",
    "        W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "        variable_summaries(W_conv1)\n",
    "        variable_summaries(b_conv1)\n",
    "        \n",
    "    with tf.name_scope(\"2nd_convolution\"):\n",
    "        W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "        variable_summaries(W_conv2)\n",
    "        variable_summaries(b_conv2)\n",
    "            \n",
    "    with tf.name_scope(\"fully_connected\"):\n",
    "        W = weight_variable([7 * 7 * 64, 1024])\n",
    "        b = bias_variable([1024])\n",
    "        h_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "        h_relu = tf.nn.relu(tf.matmul(h_flat, W) + b)\n",
    "        \n",
    "    with tf.name_scope(\"dropout\"):\n",
    "        h_drop = tf.nn.dropout(h_relu, keep_prob) \n",
    "        \n",
    "    with tf.name_scope(\"readout\"):\n",
    "        W2 = weight_variable([1024, 10])\n",
    "        b2 = bias_variable([10])\n",
    "        y_conv = tf.matmul(h_drop, W2) + b2\n",
    "        \n",
    "    with tf.name_scope(\"cross_entropy\"):\n",
    "        cross_entropy = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                labels=y_input, \n",
    "                logits=y_conv))\n",
    "        tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "        \n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "        \n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(y_conv, axis=1), tf.argmax(y_input, axis=1)) \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        \n",
    "    merged = tf.summary.merge_all()\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test graph architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    xs, ys = mnist.train.next_batch(10)\n",
    "    feed_dict = {x_input: xs, y_input: ys, keep_prob: 1}\n",
    "    __ = sess.run(merged, feed_dict=feed_dict)\n",
    "    print(np.shape(__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean summaries folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_folder(path=\"./tensorflow_summaries/train/\")\n",
    "clean_folder(path=\"./tensorflow_summaries/test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feed dict helper\n",
    "def feed_dict(train=True, dropout=1):\n",
    "    if train:\n",
    "        xs, ys = mnist.train.next_batch(100)\n",
    "        k = dropout\n",
    "    else:\n",
    "        xs, ys = mnist.test.images, mnist.test.labels\n",
    "        k = 1\n",
    "    return {x_input: xs, y_input: ys, keep_prob: 1}\n",
    "\n",
    "# dropout\n",
    "k = 0.5\n",
    "\n",
    "# using graph for training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    train_writer = tf.summary.FileWriter(\"./tensorflow_summaries/train\", sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(\"./tensorflow_summaries/test\")\n",
    "    \n",
    "    for i in range(100):\n",
    "        if i % 10 == 0:\n",
    "            summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False))\n",
    "            test_writer.add_summary(summary, i)\n",
    "            if i % 100 == 0:\n",
    "                print('Acc at epoch %s: %s' % (i, acc))\n",
    "        else:\n",
    "            summary, __ = sess.run([merged, train_step], feed_dict=feed_dict(True, k))\n",
    "            train_writer.add_summary(summary, i)\n",
    "    # test\n",
    "    out = sess.run(accuracy, feed_dict=feed_dict(False))\n",
    "    print(\"Acc. on test: %f\" % out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
