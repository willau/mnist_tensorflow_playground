{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST number classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9c63564828>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c6389e550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_train = np.shape(x_train)[0]\n",
    "idx = np.random.randint(n_train)\n",
    "vector = x_train[idx]\n",
    "img = np.reshape(vector, (28, 28))\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow and TensorBoard helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, scope='summaries'):\n",
    "    with tf.name_scope(scope):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)\n",
    "        \n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name='W')\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name='b')\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], \n",
    "                        padding='SAME', name='convolution')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
    "                          padding='SAME', name='max_pool')\n",
    "\n",
    "def apply_conv(x, shape, summarize=True):\n",
    "    W_conv = weight_variable(shape)\n",
    "    b_conv = bias_variable([shape[-1]])\n",
    "    h_conv = tf.nn.relu(conv2d(x, W_conv) + b_conv)\n",
    "    h_pool = max_pool_2x2(h_conv)\n",
    "    if summarize:\n",
    "        variable_summaries(W_conv, \"weights\")\n",
    "        variable_summaries(b_conv, \"biases\")\n",
    "    return h_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One CNN to rule them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset graph (important for batch normalization and summary)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholder\n",
    "x_input = tf.placeholder(tf.float32, [None, 784])\n",
    "y_input = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    \n",
    "    with tf.name_scope(\"reshape\"):\n",
    "        x_image = tf.reshape(x_input, [-1, 28, 28, 1])\n",
    "        tf.summary.image('input', x_image, 3)\n",
    "        \n",
    "    with tf.name_scope(\"conv1\"):\n",
    "        h1 = apply_conv(x_image, [5, 5, 1, 32])\n",
    "        \n",
    "    with tf.name_scope(\"conv2\"):\n",
    "        h2 = apply_conv(h1, [5, 5, 32, 64])\n",
    "            \n",
    "    with tf.name_scope(\"fully_connected\"):\n",
    "        W = weight_variable([7 * 7 * 64, 1024])\n",
    "        b = bias_variable([1024])\n",
    "        h_flat = tf.reshape(h2, [-1, 7 * 7 * 64])\n",
    "        h_relu = tf.nn.relu(tf.matmul(h_flat, W) + b)\n",
    "        \n",
    "    with tf.name_scope(\"dropout\"):\n",
    "        h_drop = tf.nn.dropout(h_relu, keep_prob) \n",
    "        \n",
    "    with tf.name_scope(\"readout\"):\n",
    "        W2 = weight_variable([1024, 10])\n",
    "        b2 = bias_variable([10])\n",
    "        y_conv = tf.matmul(h_drop, W2) + b2\n",
    "        \n",
    "    with tf.name_scope(\"cross_entropy\"):\n",
    "        cross_entropy = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                labels=y_input, \n",
    "                logits=y_conv))\n",
    "        tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "        \n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "        \n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(y_conv, axis=1), tf.argmax(y_input, axis=1)) \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        \n",
    "    merged = tf.summary.merge_all()\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test graph architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "CPU times: user 19.3 s, sys: 1.28 s, total: 20.6 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    xs, ys = mnist.test.images, mnist.test.labels\n",
    "    feed_dict = {x_input: xs, y_input: ys, keep_prob: 1}\n",
    "    __ = sess.run(merged, feed_dict=feed_dict)\n",
    "    print(np.shape(__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean summaries folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_folder(path=\"./tensorflow_summaries/\"):\n",
    "    for file in os.listdir(path):\n",
    "        filepath = path + file\n",
    "        if os.path.isfile(filepath):\n",
    "            os.remove(filepath)\n",
    "            \n",
    "clean_folder(path=\"./tensorflow_summaries/train/\")\n",
    "clean_folder(path=\"./tensorflow_summaries/test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model [delete random sampling later]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc at epoch 0: 0.1142\n",
      "Acc at epoch 50: 0.8961\n",
      "Acc at epoch 100: 0.945\n",
      "Acc at epoch 150: 0.9509\n",
      "Acc at epoch 200: 0.9617\n",
      "Acc at epoch 250: 0.9593\n",
      "Acc at epoch 300: 0.9655\n",
      "Acc at epoch 350: 0.9706\n",
      "Acc at epoch 400: 0.9711\n",
      "Acc at epoch 450: 0.9724\n",
      "Acc at epoch 500: 0.976\n",
      "Acc at epoch 550: 0.9777\n",
      "Acc at epoch 600: 0.9804\n",
      "Acc at epoch 650: 0.9776\n",
      "Acc at epoch 700: 0.9794\n",
      "Acc at epoch 750: 0.979\n",
      "Acc at epoch 800: 0.9836\n",
      "Acc at epoch 850: 0.9829\n",
      "Acc at epoch 900: 0.9786\n",
      "Acc at epoch 950: 0.9795\n",
      "Acc at epoch 1000: 0.9839\n",
      "Acc at epoch 1050: 0.9845\n",
      "Acc at epoch 1100: 0.9835\n",
      "Acc at epoch 1150: 0.982\n",
      "Acc at epoch 1200: 0.9846\n",
      "Acc at epoch 1250: 0.9843\n",
      "Acc at epoch 1300: 0.9852\n",
      "Acc at epoch 1350: 0.9841\n",
      "Acc at epoch 1400: 0.9828\n",
      "Acc at epoch 1450: 0.981\n",
      "Acc at epoch 1500: 0.983\n",
      "Acc at epoch 1550: 0.9845\n",
      "Acc at epoch 1600: 0.9845\n",
      "Acc at epoch 1650: 0.9817\n",
      "Acc at epoch 1700: 0.9853\n",
      "Acc at epoch 1750: 0.983\n",
      "Acc at epoch 1800: 0.9879\n",
      "Acc at epoch 1850: 0.9867\n",
      "Acc at epoch 1900: 0.986\n",
      "Acc at epoch 1950: 0.9869\n",
      "Acc. on test: 0.986100\n",
      "CPU times: user 25min 46s, sys: 4min 10s, total: 29min 57s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# feed dict helper\n",
    "def feed_dict(train=True, dropout=1):\n",
    "    batch_size = 50\n",
    "    if train:\n",
    "        xs, ys = mnist.train.next_batch(batch_size)\n",
    "        k = dropout\n",
    "    else:\n",
    "        xs, ys = mnist.test.images, mnist.test.labels\n",
    "        k = 1\n",
    "    return {x_input: xs, y_input: ys, keep_prob: dropout}\n",
    "\n",
    "# dropout: keep probability\n",
    "k = 0.5\n",
    "\n",
    "# using graph for training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    train_writer = tf.summary.FileWriter(\"./tensorflow_summaries/train\", sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(\"./tensorflow_summaries/test\")\n",
    "    \n",
    "    for i in range(2000):\n",
    "        if i % 50 == 0:\n",
    "            summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False))\n",
    "            test_writer.add_summary(summary, i)\n",
    "            print('Acc at epoch %s: %s' % (i, acc))\n",
    "        else:\n",
    "            summary, __ = sess.run([merged, train_step], feed_dict=feed_dict(True, k))\n",
    "            train_writer.add_summary(summary, i)\n",
    "        \n",
    "    # test\n",
    "    out = sess.run(accuracy, feed_dict=feed_dict(False))\n",
    "    print(\"Acc. on test: %f\" % out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
